{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872df70d-218c-4efc-b193-ce9d6b3bbd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552bd24f-d545-491d-aa8f-25ab0e71ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the results folder\n",
    "results_folder = './results'\n",
    "\n",
    "# List to store model results\n",
    "models_data = []\n",
    "\n",
    "# Reading all JSON files from the folder\n",
    "for filename in os.listdir(results_folder):\n",
    "    if filename.endswith('.json'):\n",
    "        filepath = os.path.join(results_folder, filename)\n",
    "        with open(filepath, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            # Extracting flat information from JSON\n",
    "            flattened_data = {\n",
    "                'model_name': data['model_name'],\n",
    "                'accuracy': data['accuracy'],\n",
    "                'weighted_avg_f1_score': data['classification_report']['weighted avg']['f1-score'],\n",
    "                'total_training_time': pd.to_timedelta(data['total_training_time']).total_seconds()\n",
    "            }\n",
    "            models_data.append(flattened_data)\n",
    "\n",
    "# Creating a DataFrame from the data\n",
    "comparison_df = pd.DataFrame(models_data)\n",
    "\n",
    "# Converting training_time to seconds for comparison\n",
    "comparison_df['total_training_time'] = pd.to_timedelta(comparison_df['total_training_time']).dt.total_seconds()\n",
    "\n",
    "# Displaying the comparison\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78e76d-d29e-407d-b24b-45e85a72d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from the data\n",
    "comparison_df = pd.DataFrame(models_data)\n",
    "\n",
    "# Displaying the comparison\n",
    "print(comparison_df)\n",
    "\n",
    "# Selecting the model with the highest accuracy\n",
    "best_model_accuracy = comparison_df.loc[comparison_df['accuracy'].idxmax()]\n",
    "print(f'\\nBest model based on accuracy: \\n{best_model_accuracy}')\n",
    "\n",
    "# Selecting the model with the highest weighted average F1-score\n",
    "best_model_f1 = comparison_df.loc[comparison_df['weighted_avg_f1_score'].idxmax()]\n",
    "print(f'\\nBest model based on weighted average F1-score:\\n{best_model_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba00e20-e7f7-4e6c-9cd9-d5e3bdee7134",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_accuracy = comparison_df['accuracy'].min() - 0.001\n",
    "max_accuracy = comparison_df['accuracy'].max() + 0.001\n",
    "min_f1 = comparison_df['weighted_avg_f1_score'].min() - 0.001\n",
    "max_f1 = comparison_df['weighted_avg_f1_score'].max() + 0.001\n",
    "min_time = comparison_df['total_training_time'].min() - 0.1\n",
    "max_time = comparison_df['total_training_time'].max() + 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548559ce-0554-4e70-b3ff-14bdb5266b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bar plots\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Bar plot for accuracy\n",
    "sns.barplot(data=comparison_df, x='accuracy', y='model_name', palette='viridis', hue='model_name', legend=False)\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Model Name')\n",
    "plt.xlim(min_accuracy, max_accuracy)\n",
    "\n",
    "# Adding values on bars\n",
    "for index, value in enumerate(comparison_df['accuracy']):\n",
    "    plt.text(value, index, f'{value:.4f}')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Bar plot for weighted average F1-score\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.barplot(data=comparison_df, x='weighted_avg_f1_score', y='model_name', palette='viridis', hue='model_name', legend=False)\n",
    "plt.title('Model Weighted Average F1-Score Comparison')\n",
    "plt.xlabel('Weighted Avg F1-Score')\n",
    "plt.ylabel('Model Name')\n",
    "plt.xlim(min_f1, max_f1)\n",
    "\n",
    "# Adding values on bars\n",
    "for index, value in enumerate(comparison_df['weighted_avg_f1_score']):\n",
    "    plt.text(value, index, f'{value:.4f}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640445e-85fe-47e8-b566-98c881edc1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for training time\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.barplot(data=comparison_df, x='total_training_time', y='model_name', hue='model_name', legend=False)\n",
    "plt.title('Model Training Time Comparison')\n",
    "plt.xlabel('Training Time (s)')\n",
    "plt.ylabel('Model Name')\n",
    "plt.xlim(min_time - 0.9, max_time + 0.9)\n",
    "# Adding values on bars\n",
    "for index, value in enumerate(comparison_df['total_training_time']):\n",
    "    plt.text(value, index, f'{value:.2f}s')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd533c6f-7b17-4d8e-8f46-0aa2de634b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Scatter plot for accuracy\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.scatterplot(data=comparison_df, x='accuracy', y='model_name', hue='model_name', palette='viridis', s=100, legend=False)\n",
    "plt.title('Model Accuracy Comparison (Scatter Plot)')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Model Name')\n",
    "plt.xlim(min_accuracy, max_accuracy)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for weighted average F1-score\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.scatterplot(data=comparison_df, x='weighted_avg_f1_score', y='model_name', hue='model_name', palette='viridis', s=100, legend=False)\n",
    "plt.title('Model Weighted Average F1-Score Comparison (Scatter Plot)')\n",
    "plt.xlabel('Weighted Avg F1-Score')\n",
    "plt.ylabel('Model Name')\n",
    "plt.xlim(min_f1, max_f1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for training time\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.scatterplot(data=comparison_df, x='total_training_time', y='model_name', hue='model_name', palette='viridis', s=100, legend=False)\n",
    "plt.title('Model Training Time Comparison (Scatter Plot)')\n",
    "plt.xlabel('Training Time (s)')\n",
    "plt.ylabel('Model Name')\n",
    "plt.xlim(min_time, max_time)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
